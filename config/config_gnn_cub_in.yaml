mode: "pseudo" #train/test/hyper_search/pretraining
application: "DML"

models:
  encoder_params:
    pretrained_path: "no" #"pretrained/0.13352464550979068neck_bn_inception_cub.pth" 
    net_type: "bn_inception"
    neck: 0
    last_stride: 0
    final_drop: 0 #0.5
    stoch_depth: 1 #0.8
    weight_norm: 0
    red: 4
    bn_inception:
      embed: 1
      sz_embedding: 512

  gnn_params:
    pretrained_path: "no"
    use_edge_encoder: 0
    use_edge_model: 0
    use_node_encoder: 0
    red: 1
    cat: 0
    every: 0
    gnn:
      num_layers: 2
      aggregator: "add"
      num_heads: 4 
      attention: "dot" #"dot_pygeo"
      mlp: 1
      dropout_mlp: 0.1
      norm1: 1
      norm2: 1 
      res1: 1
      res2: 1
      dropout_1: 0.1
      dropout_2: 0.1
      mult_attr: 0
    edge:
      fc_dims: [2048]
      dropout_p: 0.4
      use_batchnorm: 0
    node_encoder:
      fc_dims: [2048]
      dropout_p: 0.4
      use_batchnorm: 0
    edge_encoder:
      fc_dims: [2048]
      dropout_p: 0.4
      use_batchnorm: 0
    classifier:
      neck: 0
      num_classes: 100
      dropout_p: 0.4
      use_batchnorm: 0

graph_params:
  sim_type: "correlation"
  thresh: 0
  set_negative: "hard"

dataset:
  dataset_path: "../../datasets/CUB_200_2011"
  dataset_short: "cub"
  num_classes: 100
  number_aug: 2
  magnitude: 27
  trans: "GLorig"
  sampling: "no"
  bssampling: "no" #"NumberSampler"
  val: 0
  nb_workers: 4

train_params:
  num_classes_iter: 6 #24 #12 #24 #6
  num_elements_class: 9 #9 #3 #9 #9
  lr: 0.0001563663718906821 #0.0001488349866231485 #0.0003369018908950139 #0.0001488349866231485 #0.0001563663718906821 
  weight_decay: 6.059722614369727e-06 #6.059722614369727e-06 #3.009943636752097e-14 #6.059722614369727e-06 #6.059722614369727e-06
  num_epochs: 70
  is_apex: 0
  temperatur: 0.2 #0.2 #0.41226733899858015 #0.2 #0.2
  output_train_enc: "plain" #"plain"
  output_train_gnn: "plain" #"plain"
  loss_fn:
    fns: "lsce_lsgnn" #ce/focalce can be used instead of lsce and lsgnn/focalgnn instead of gnn, rest can be added by ce_gnn_center...
    scaling_ce: 1
    scaling_gnn: 1
    scaling_center: 0.5
    scaling_triplet: 1
    scaling_of: 1
    scaling_of_pre: 1
    scaling_distill: 1
    soft_temp: 1
    feats: "results/0.8532544378698225_cub_1601148947.5862918/feats.json"
    preds: "results/0.8532544378698225_cub_1601148947.5862918/preds.json"

eval_params:
  cat: 0
  re_rank: 0
  lamb: 0.3
  k1: 20
  k2: 6
  output_test_enc: "plain" #"plain"
  output_test_gnn: "plain"
  







